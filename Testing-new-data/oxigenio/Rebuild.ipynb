{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"./content\")\n",
    "\n",
    "lm_dir = \"tf-levenberg-marquardt\"\n",
    "if not os.path.exists(lm_dir):\n",
    "  !git clone https://github.com/fabiodimarco/$lm_dir\n",
    "\n",
    "os.chdir(lm_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scaler = StandardScaler()\n",
    "out_scaler = StandardScaler()\n",
    "\n",
    "def getData():\n",
    "    df_orig = pd.read_excel(\"../../../data.xlsx\")    \n",
    "    df = pd.DataFrame(scaler.fit_transform(df_orig), columns=df_orig.columns)\n",
    "    df_denorm = pd.DataFrame(scaler.inverse_transform(df), columns=df.columns)\n",
    "    return (df_orig, df, df_denorm)\n",
    "\n",
    "def create_dataframe(df, output):\n",
    "    x1, x2, x3, x4, x5  = df['x1'], df['x2'], df['x3'], df['x4'], df['x5']\n",
    "\n",
    "    input = np.vstack([x1, x2, x3, x4, x5 ]).T\n",
    "    output = np.array(df[output])\n",
    "    scaler.fit(output.reshape(-1, 1))\n",
    "    return output, input\n",
    "\n",
    "def test_out_scaler():\n",
    "    out = df_orig[\"y1\"].values.reshape(-1, 1)  \n",
    "    plt.plot(out, label='Original')\n",
    "    out_scaler.fit(out)\n",
    "    norm = out_scaler.transform(out)\n",
    "    plt.plot(norm, label='Normalizado')\n",
    "    plt.plot(out_scaler.inverse_transform(norm), label='desnormalizado')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def show_norm(label):\n",
    "    df_orig.plot(title=f\"{label}: Original data\")\n",
    "    df.plot(title=f\"{label}: Normalized data\")\n",
    "    df_denorm.plot(title=f\"{label}: Denormalized data\")\n",
    "\n",
    "df_orig, df, df_denorm = getData()\n",
    "output, input = create_dataframe(df, output=\"y1\")\n",
    "test_out_scaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras import initializers\n",
    "import levenberg_marquardt as lm\n",
    "\n",
    "# layers, neurons\n",
    "class ShuffleArchitecture:\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, act_h, act_o, param_reg):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.output_size = output_size\n",
    "        self.act_h = act_h\n",
    "        self.act_o = act_o\n",
    "        self.regularizer = regularizers.L2(param_reg)\n",
    "        self.initializer = initializers.RandomUniform(minval=-0.5, maxval=0.5, seed=np.random.randint(1, 10000))\n",
    "\n",
    "    def set_architecture(self):\n",
    "        self.model = tf.keras.Sequential()\n",
    "        self.model.add(tf.keras.layers.Dense(self.hidden_sizes[0],\n",
    "                        input_shape=(self.input_size,),\n",
    "                        activation=self.act_h,\n",
    "                        kernel_regularizer=self.regularizer,\n",
    "                        kernel_initializer=self.initializer,                        \n",
    "                        ))  # input layer\n",
    "        \n",
    "        for size in self.hidden_sizes[1:]:  # hidden layers\n",
    "            self.model.add(tf.keras.layers.Dense(size,\n",
    "                            activation=self.act_h,\n",
    "                            kernel_regularizer=self.regularizer,\n",
    "                            kernel_initializer=self.initializer,  \n",
    "                        ))\n",
    "\n",
    "        self.model.add(tf.keras.layers.Dense(self.output_size,\n",
    "                        activation=self.act_o,\n",
    "                        kernel_regularizer=self.regularizer,\n",
    "                        kernel_initializer=self.initializer,  \n",
    "                        ))  # output layer\n",
    "\n",
    "    def create_model(self, _learning_rate):\n",
    "        self.model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=_learning_rate),\n",
    "            loss=tf.keras.losses.MeanSquaredError())\n",
    "\n",
    "        self.lm_model = lm.ModelWrapper(\n",
    "            tf.keras.models.clone_model(self.model))\n",
    "\n",
    "        self.lm_model.compile(\n",
    "            optimizer=tf.keras.optimizers.SGD(learning_rate=_learning_rate),\n",
    "            loss=lm.MeanSquaredError())\n",
    "        return(self.lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class Rebuild:\n",
    "    def __init__(self):\n",
    "        self.df = pd.read_excel(f\"../../better_results.xlsx\")        \n",
    "\n",
    "    def LoadModelWeights(self, model, fileName):        \n",
    "        path = f\"../models/{fileName}.keras\"\n",
    "        model.load_weights(path)\n",
    "\n",
    "    def LoadPrevDataset(self, fileName):\n",
    "        fileName = fileName.replace(\"model\", \"dataset\")\n",
    "        pos = fileName.rfind(\"_\")\n",
    "        path = f\"../dataset/{fileName[:pos]}.pkl\" \n",
    "        with open(path, 'rb') as f:\n",
    "            _data, _train, _vt, _val, _test = pickle.load(f)\n",
    "        self._data, self._train, self._vt, self._val, self._test = _data, _train, _vt, _val, _test    \n",
    "    \n",
    "    def setArchitecture(self, _hidden_sizes, _pg, _lr):\n",
    "        shuffler = ShuffleArchitecture(input_size  = 5,\n",
    "                                        hidden_sizes = _hidden_sizes,\n",
    "                                        output_size = 1,\n",
    "                                        act_h = 'tanh',\n",
    "                                        act_o = 'linear',\n",
    "                                        param_reg=_pg)\n",
    "        shuffler.set_architecture()\n",
    "        return(shuffler.create_model(_lr))            \n",
    "\n",
    "    def getArchitecture(self, architecture):\n",
    "        hidden_size = [int(x) for x in architecture.split(\"[\")[1].split(\"]\")[0].split(\", \")]\n",
    "        regularizer = float(architecture.split(\"regularizer=\")[1].split(\",\")[0])\n",
    "        learning_rate = float(architecture.split(\"learning_rate=\")[1])\n",
    "        return hidden_size, regularizer, learning_rate\n",
    "\n",
    "    def PlotResults(self, original_values, predicted_values):\n",
    "        titles = ['Original vs. Preditos (Completo)',\n",
    "                    'Original vs. Preditos (Teste)',\n",
    "                    'Original vs. Preditos (Validação)',\n",
    "                    'Original vs. Preditos (Validação e Teste)']\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            ax.plot(original_values[i], label='Original')\n",
    "            ax.plot(predicted_values[i], label='Preditos')\n",
    "            ax.set_title(titles[i])\n",
    "            ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def predictResults(self):\n",
    "        pred = self.lm_model.predict(self._data[0]).flatten()\n",
    "        test_pred = self.lm_model.predict(self._test[0]).flatten()\n",
    "        val_pred = self.lm_model.predict(self._val[0]).flatten()\n",
    "        vt_pred = self.lm_model.predict(self._vt[0]).flatten()\n",
    "\n",
    "        # Calculando as metricas com a saida desnormalizada\n",
    "        pred_denorm = out_scaler.inverse_transform(pred.reshape(-1, 1))\n",
    "        test_pred_denorm = out_scaler.inverse_transform(test_pred.reshape(-1, 1))\n",
    "        val_pred_denorm = out_scaler.inverse_transform(val_pred.reshape(-1, 1))\n",
    "        vt_pred_denorm = out_scaler.inverse_transform(vt_pred.reshape(-1, 1))\n",
    "\n",
    "        out_denorm = out_scaler.inverse_transform(self._data[1].reshape(-1, 1))\n",
    "        test_denorm = out_scaler.inverse_transform(self._test[1].reshape(-1, 1))\n",
    "        val_denorm = out_scaler.inverse_transform(self._val[1].reshape(-1, 1))\n",
    "        vt_denorm = out_scaler.inverse_transform(self._vt[1].reshape(-1, 1))\n",
    "        \n",
    "        original_values = [out_denorm, test_denorm, val_denorm, vt_denorm]\n",
    "        predicted_values = [pred_denorm, test_pred_denorm, val_pred_denorm, vt_pred_denorm]\n",
    "        return (original_values, predicted_values)\n",
    "\n",
    "\n",
    "    def rebuildFullNet(self, model):\n",
    "        for file_model, architecture in zip(self.df[\"model\"], self.df[\"Architecture\"]):\n",
    "            if model == file_model:\n",
    "                hidden_size, regularizer, learning_rate = self.getArchitecture(architecture)\n",
    "                self.lm_model = self.setArchitecture(hidden_size, regularizer, learning_rate)\n",
    "                self.LoadModelWeights(self.lm_model, file_model)\n",
    "                self.LoadPrevDataset(file_model)\n",
    "                original_values, predicted_values = self.predictResults()\n",
    "                self.PlotResults(original_values, predicted_values)\n",
    "    \n",
    "\n",
    "    def LoadNewDataset(self):\n",
    "        inputScaler = StandardScaler()\n",
    "        df_orig = pd.read_excel(f\"../../../data-test.xlsx\")\n",
    "        df = pd.DataFrame(inputScaler.fit_transform(df_orig), columns=df_orig.columns)\n",
    "        x1, x2, x3, x4, x5  = df['x1'], df['x2'], df['x3'], df['x4'], df['x5']\n",
    "        input = np.vstack([x1, x2, x3, x4, x5]).T\n",
    "        return (input, df_orig)\n",
    "\n",
    "    def PlotNewDataResults(self, df, label):\n",
    "        columns = df.columns[5:]\n",
    "        for column in columns:\n",
    "            plt.scatter(df.index, df[column], label=column)\n",
    "        plt.xlabel('Amostra')\n",
    "        plt.ylabel('Valores Preditos pela rede')\n",
    "        plt.title(f'Gráfico de Dispersão da {label}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def mean_std(self, df):\n",
    "        df_out = df.iloc[:, 5:]\n",
    "        mean = df_out.mean(axis=1)\n",
    "        std = df_out.std(axis=1)\n",
    "        df[\"media\"] = mean\n",
    "        df[\"desvio padrao\"] = std\n",
    "        df.to_excel('../../results.xlsx', index=False)\n",
    "        display(df)\n",
    "        \n",
    "\n",
    "    def TestNewData(self, label):\n",
    "        input, df = self.LoadNewDataset()\n",
    "        for file_model, architecture in zip(self.df[\"model\"], self.df[\"Architecture\"]):\n",
    "            hidden_size, regularizer, learning_rate = self.getArchitecture(architecture)\n",
    "            self.lm_model = self.setArchitecture(hidden_size, regularizer, learning_rate)\n",
    "            self.LoadModelWeights(self.lm_model, file_model)\n",
    "            pred = self.lm_model.predict(input).flatten()\n",
    "            pred_denorm = out_scaler.inverse_transform(pred.reshape(-1, 1))\n",
    "            df[file_model] = pred_denorm\n",
    "        self.PlotNewDataResults(df, label)\n",
    "        self.mean_std(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rebuilder = Rebuild()\n",
    "Rebuilder.TestNewData(label=\"oxigenio\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
